(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{431:function(t,r,e){"use strict";e.r(r);var a=e(10),n=Object(a.a)({},(function(){var t=this,r=t.$createElement,e=t._self._c||r;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("p",[t._v("主要依赖于Pytorch和TensorFlow框架。")]),t._v(" "),e("h2",{attrs:{id:"数据"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据"}},[t._v("#")]),t._v(" 数据")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://blog.csdn.net/weixin_42516475/article/details/117116694",target:"_blank",rel:"noopener noreferrer"}},[t._v("torch.zeros_like() 和 torch.zeros()的区别_Kevinllli的博客-CSDN博客_torch銆倆eros"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://www.zhihu.com/question/320473273/answer/655887618",target:"_blank",rel:"noopener noreferrer"}},[t._v("pytorch中long.tensor和普通的tensor有什么不同？ - 知乎 (zhihu.com)"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/qq_34914551/article/details/88700334",target:"_blank",rel:"noopener noreferrer"}},[t._v("Pytorch中，将label变成one hot编码的两种方式_我的博客有点东西-CSDN博客"),e("OutboundLink")],1)]),t._v(" "),e("li"),t._v(" "),e("li")]),t._v(" "),e("h2",{attrs:{id:"正则化"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#正则化"}},[t._v("#")]),t._v(" 正则化")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://blog.csdn.net/m0_37870649/article/details/82025238",target:"_blank",rel:"noopener noreferrer"}},[t._v("batch norm、relu、dropout 等的相对顺序和BN、dropout的几个问题和思考_永远飞翔的鸟-CSDN博客"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/qq_24739717/article/details/103121955",target:"_blank",rel:"noopener noreferrer"}},[t._v("学习笔记|Pytorch使用教程23(正则化之weight_decay)_NotFound1911的博客-CSDN博客"),e("OutboundLink")],1)]),t._v(" "),e("li")]),t._v(" "),e("h2",{attrs:{id:"优化器"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#优化器"}},[t._v("#")]),t._v(" 优化器")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://www.pianshen.com/article/54661339693/",target:"_blank",rel:"noopener noreferrer"}},[t._v("深度学习中的常见正则化方法(Regularization)以及优化器中的WeightDecay参数详解 - 程序员大本营 (pianshen.com)"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/scut_salmon/article/details/82414730",target:"_blank",rel:"noopener noreferrer"}},[t._v("torch代码解析 为什么要使用optimizer.zero_grad()_scut_salmon的博客-CSDN博客"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/104472245",target:"_blank",rel:"noopener noreferrer"}},[t._v("Pytorch Leaning Rate Scheduler 坑s - 知乎 (zhihu.com)"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/shanglianlm/article/details/85143614",target:"_blank",rel:"noopener noreferrer"}},[t._v("PyTorch学习之六个学习率调整策略_mingo_敏-CSDN博客_pytorch 学习率"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://www.cnblogs.com/wuliytTaotao/p/11101652.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Adam和学习率衰减（learning rate decay） - wuliytTaotao - 博客园 (cnblogs.com)"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/sinat_36618660/article/details/100026261",target:"_blank",rel:"noopener noreferrer"}},[t._v("深度学习中的Adam优化算法详解_sinat_36618660的博客-CSDN博客_adam算法论文"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/weixin_39228381/article/details/108548413",target:"_blank",rel:"noopener noreferrer"}},[t._v("pytorch优化器详解：Adam_拿铁大侠的博客-CSDN博客"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/qq_21980099/article/details/106329354",target:"_blank",rel:"noopener noreferrer"}},[t._v("pytorch 权重weight 与 梯度grad 可视化_Rainbow-CSDN博客_pytorch查看梯度"),e("OutboundLink")],1)]),t._v(" "),e("li")]),t._v(" "),e("h2",{attrs:{id:"损失函数"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#损失函数"}},[t._v("#")]),t._v(" 损失函数")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://blog.csdn.net/weixin_41519463/article/details/101217066",target:"_blank",rel:"noopener noreferrer"}},[t._v("Binary_Cross_Entropy"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/qq_37344125/article/details/104326946",target:"_blank",rel:"noopener noreferrer"}},[t._v("为什么正则化能够解决过拟合问题？_一扣解千愁的博客-CSDN博客_为什么正则化能处理过拟合"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/qq_22210253/article/details/85229988",target:"_blank",rel:"noopener noreferrer"}},[t._v("Pytorch详解NLLLoss和CrossEntropyLoss_豪哥的博客-CSDN博客_nllloss"),e("OutboundLink")],1)]),t._v(" "),e("li")]),t._v(" "),e("h2",{attrs:{id:"标签"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#标签"}},[t._v("#")]),t._v(" 标签")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://www.zhihu.com/question/22464082",target:"_blank",rel:"noopener noreferrer"}},[t._v("机器学习里经常出现ground truth这个词，能否准确解释一下？ - 知乎 (zhihu.com)"),e("OutboundLink")],1)]),t._v(" "),e("li")]),t._v(" "),e("h2",{attrs:{id:"过拟合"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#过拟合"}},[t._v("#")]),t._v(" 过拟合")]),t._v(" "),e("h2",{attrs:{id:"模型配置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#模型配置"}},[t._v("#")]),t._v(" 模型配置")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/107203828",target:"_blank",rel:"noopener noreferrer"}},[t._v("pytorch保存和加载模型 - 知乎 (zhihu.com)"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/bigFatCat_Tom/article/details/90722261",target:"_blank",rel:"noopener noreferrer"}},[t._v("【PyTorch】state_dict详解_安静-CSDN博客"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://www.cnblogs.com/jfdwd/p/11194378.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("pytorch 状态字典:state_dict 模型和参数保存 - 交流_QQ_2240410488 - 博客园 (cnblogs.com)"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/foneone/article/details/107099060",target:"_blank",rel:"noopener noreferrer"}},[t._v("Pytorch_hook机制的理解及利用register_forward_hook(hook)中间层输出_越努力 越幸运-CSDN博客_register_forward_hook"),e("OutboundLink")],1)]),t._v(" "),e("li")]),t._v(" "),e("h2",{attrs:{id:"可视化"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#可视化"}},[t._v("#")]),t._v(" 可视化")]),t._v(" "),e("h3",{attrs:{id:"matplotlib"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#matplotlib"}},[t._v("#")]),t._v(" Matplotlib")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://stackoverflow.com/questions/31768031/plotting-points-on-the-surface-of-a-sphere-in-pythons-matplotlib?answertab=active#tab-top",target:"_blank",rel:"noopener noreferrer"}},[t._v("Plotting points on the surface of a sphere in Python's matplotlib - Stack Overflow"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/ygdxt/article/details/86618606",target:"_blank",rel:"noopener noreferrer"}},[t._v("深入理解 Matplotlib 3D 绘图函数 plot_surface 的 rstride 和 cstride 参数_月小水长-CSDN博客"),e("OutboundLink")],1)])]),t._v(" "),e("h3",{attrs:{id:"t-sne"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#t-sne"}},[t._v("#")]),t._v(" t-SNE")]),t._v(" "),e("h3",{attrs:{id:"其他"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#其他"}},[t._v("#")]),t._v(" 其他")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://askubuntu.com/questions/1127011/win10-linux-subsystem-libgl-error-no-matching-fbconfigs-or-visuals-found-libgl",target:"_blank",rel:"noopener noreferrer"}},[t._v("nvidia - Win10 linux subsystem libGL error: No matching fbConfigs or visuals found libGL error: failed to load driver: swrast - Ask Ubuntu"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.csdn.net/sunxb10/article/details/81036693",target:"_blank",rel:"noopener noreferrer"}},[t._v("Python格式化字符串f-string概览_sunxb10的博客-CSDN博客"),e("OutboundLink")],1)]),t._v(" "),e("li")]),t._v(" "),e("h2",{attrs:{id:"疑问"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#疑问"}},[t._v("#")]),t._v(" 疑问")]),t._v(" "),e("ul",[e("li",[t._v("为什么二值交叉熵会导致过拟合？")])])])}),[],!1,null,null,null);r.default=n.exports}}]);