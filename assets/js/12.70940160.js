(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{419:function(a,t,s){"use strict";s.r(t);var e=s(10),r=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("p",[a._v("将TIMIT数据集分为用于训练PLDA的域内数据和用于测试的Test集[⛳以后再写随机划分脚本]，取前130人作为域内数据。使用预训练模型（详见"),s("a",{attrs:{href:"http://zhouwenjun2020.gitee.io/my-vue/pages/61850b/#%E5%B7%B2%E7%9F%A5%E6%9D%A1%E4%BB%B6",target:"_blank",rel:"noopener noreferrer"}},[a._v("使用预训练Xvector模型进行测试"),s("OutboundLink")],1),a._v("）中域外数据的PLDA模型和LDA矩阵，但是重新训练均值向量。")]),a._v(" "),s("h2",{attrs:{id:"主代码分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#主代码分析"}},[a._v("#")]),a._v(" 主代码分析")]),a._v(" "),s("p",[a._v("参考脚本：sre16/0003_sre16_v2_1a/run.sh stage8")]),a._v(" "),s("h3",{attrs:{id:"获取中心化所需的均值向量"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#获取中心化所需的均值向量"}},[a._v("#")]),a._v(" 获取中心化所需的均值向量")]),a._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$train_cmd")]),a._v(" exp/xvectors_domain/log/compute_mean.log "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  ivector-mean scp:exp/xvectors_domain/xvector.scp "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  exp/xvectors_domain/mean.vec "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("||")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("exit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br")])]),s("ul",[s("li",[a._v("中心化只使用域内数据，所谓中心化，就是取与你需要去中心化的数据集最接近的已知数据集的均值")])]),a._v(" "),s("h3",{attrs:{id:"自适应得到域内plda"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#自适应得到域内plda"}},[a._v("#")]),a._v(" 自适应得到域内PLDA")]),a._v(" "),s("p",[a._v("该阶段使用预训练模型"),s("code",[a._v("exp/xvectors_sre_combined/plda")]),a._v("，由域外数据得到")]),a._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$train_cmd")]),a._v(" exp/xvectors_domain/log/plda_adapt.log "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  ivector-adapt-plda --within-covar-scale"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.75")]),a._v(" --between-covar-scale"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.25")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  exp/xvectors_sre_combined/plda "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"ark:ivector-subtract-global-mean scp:exp/xvectors_domain/xvector.scp ark:- | transform-vec exp/xvectors_sre_combined/transform.mat ark:- ark:- | ivector-normalize-length ark:- ark:- |"')]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  exp/xvectors_domain/plda_adapt "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("||")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("exit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br")])]),s("h3",{attrs:{id:"直接训练域内plda模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#直接训练域内plda模型"}},[a._v("#")]),a._v(" 直接训练域内PLDA模型")]),a._v(" "),s("p",[a._v("需要"),s("code",[a._v("data/domain/spk2utt")])]),a._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$train_cmd")]),a._v(" exp/xvectors_domain/log/plda.log "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  ivector-compute-plda ark:data/domain/spk2utt "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"ark:ivector-subtract-global-mean scp:exp/xvectors_domain/xvector.scp ark:- | transform-vec exp/xvectors_sre_combined/transform.mat ark:- ark:- | ivector-normalize-length ark:-  ark:- |"')]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  exp/xvectors_domain/plda "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("||")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("exit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br")])]),s("h3",{attrs:{id:"plda打分"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#plda打分"}},[a._v("#")]),a._v(" PLDA打分")]),a._v(" "),s("p",[a._v("为了方便考虑分析各种模型下的性能，对PLDA打分过程进行改进：")]),a._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("meanVec")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("exp/xvectors_sre_combined/mean.vec\n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("LDA")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("exp/xvectors_sre_combined/transform.mat\n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("PLDA")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("exp/xvectors_sre_combined/plda\n"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$train_cmd")]),a._v(" exp/scores/log/scoring.log "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  ivector-plda-scoring --normalize-length"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("true "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  --num-utts"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("ark:exp/xvectors_enroll/num_utts.ark "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v("\"ivector-copy-plda --smoothing=0.0 '"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$PLDA")]),a._v("' - |\"")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v("\"ark:ivector-mean ark:data/test/enroll/spk2utt scp:exp/xvectors_enroll/xvector.scp ark:- | ivector-subtract-global-mean '"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$meanVec")]),a._v("' ark:- ark:- | transform-vec '"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$LDA")]),a._v("' ark:- ark:- | ivector-normalize-length ark:- ark:- |\"")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v("\"ark:ivector-subtract-global-mean exp/xvectors_domain/mean.vec scp:exp/xvectors_eval/xvector.scp ark:- | transform-vec '"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$LDA")]),a._v("' ark:- ark:- | ivector-normalize-length ark:- ark:- |\"")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v("\"cat '"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$trials")]),a._v("' | awk '{print "),s("span",{pre:!0,attrs:{class:"token entity",title:"\\\\"}},[a._v("\\\\")]),a._v("\\"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$2")]),a._v(", "),s("span",{pre:!0,attrs:{class:"token entity",title:"\\\\"}},[a._v("\\\\")]),a._v("\\"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$1")]),a._v("}' |\"")]),a._v(" exp/scores/eval_scores "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("||")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("exit")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("eer")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token variable"}},[s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$(")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("paste")]),a._v(" $trials exp/scores/eval_scores "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("awk")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v("'{print "),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$6")]),a._v(", "),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$3")]),a._v("}'")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" compute-eer - "),s("span",{pre:!0,attrs:{class:"token operator"}},[s("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[a._v("2")]),a._v(">")]),a._v("/dev/null"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v(")")])]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("echo")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"EER: '),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("${eer}")]),a._v('%"')]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br"),s("span",{staticClass:"line-number"},[a._v("6")]),s("br"),s("span",{staticClass:"line-number"},[a._v("7")]),s("br"),s("span",{staticClass:"line-number"},[a._v("8")]),s("br"),s("span",{staticClass:"line-number"},[a._v("9")]),s("br"),s("span",{staticClass:"line-number"},[a._v("10")]),s("br"),s("span",{staticClass:"line-number"},[a._v("11")]),s("br"),s("span",{staticClass:"line-number"},[a._v("12")]),s("br")])]),s("h3",{attrs:{id:"结果与分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#结果与分析"}},[a._v("#")]),a._v(" 结果与分析")]),a._v(" "),s("table",[s("thead",[s("tr",[s("th",[a._v("中心化")]),a._v(" "),s("th",[a._v("LDA")]),a._v(" "),s("th",[a._v("PLDA")]),a._v(" "),s("th",[a._v("EER(%)")])])]),a._v(" "),s("tbody",[s("tr",[s("td",[a._v("xvectors_sre16_major")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("6.4")])]),a._v(" "),s("tr",[s("td",[a._v("xvectors_domain")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("8.4")])]),a._v(" "),s("tr",[s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("6.4")])]),a._v(" "),s("tr",[s("td",[a._v("xvectors_domain")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_domain（自适应）")]),a._v(" "),s("td",[a._v("6.4")])]),a._v(" "),s("tr",[s("td",[a._v("xvectors_sre16_major")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_domain（自适应）")]),a._v(" "),s("td",[a._v("4.8")])]),a._v(" "),s("tr",[s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_domain（自适应）")]),a._v(" "),s("td",[a._v("4.8")])]),a._v(" "),s("tr",[s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_domain")]),a._v(" "),s("td",[a._v("5.6")])]),a._v(" "),s("tr",[s("td",[a._v("xvectors_domain")]),a._v(" "),s("td",[a._v("xvectors_sre_combined")]),a._v(" "),s("td",[a._v("xvectors_domain")]),a._v(" "),s("td",[a._v("8.2")])])])]),a._v(" "),s("ul",[s("li",[s("p",[a._v("中心化使用域内数据效果不理想，原因是100人数据实在是太少了，反而不如大规模数据来得准确；⚠️后期需要调整域内spk数")])]),a._v(" "),s("li",[s("p",[a._v("用域内数据自适应得到的PLDA比直接训练的要好")])]),a._v(" "),s("li",[s("p",[a._v("⚠️待补充：LDA也用域内数据会怎样？")]),a._v(" "),s("p",[a._v("一般来说，域内数据都是无标签的，因此无法训练LDA矩阵")])])]),a._v(" "),s("h2",{attrs:{id:"ivector-compute-plda"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ivector-compute-plda"}},[a._v("#")]),a._v(" ivector-compute-plda")]),a._v(" "),s("p",[a._v("为一组Ivector计算PLDA，用spk2utt中的说话人信息计算类内和类间方差")]),a._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("Usage:  ivector-compute-plda [options] <spk2utt-rspecifier> <ivector-rspecifier> <plda-out>\ne.g.:\n ivector-compute-plda ark:spk2utt ark,s,cs:ivectors.ark plda\n\nOptions:\n  --binary: Write output in binary mode (bool, default = true)\n  --num-em-iters: Number of iterations of E-M used for PLDA estimation (int, default = 10)\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br"),s("span",{staticClass:"line-number"},[a._v("6")]),s("br"),s("span",{staticClass:"line-number"},[a._v("7")]),s("br")])]),s("h2",{attrs:{id:"ivector-adapt-plda"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ivector-adapt-plda"}},[a._v("#")]),a._v(" ivector-adapt-plda")]),a._v(" "),s("p",[a._v("用非监督自适应数据Ivector从与训练数据不同的域自适应得到PLDA对象")]),a._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("Usage: ivector-adapt-plda "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("options"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("plda-in"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("ivectors-rspecifier"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("plda-out"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\ne.g.: ivector-adapt-plda plda ark:ivectors.ark plda.adapted\n\nOptions:\n  --between-covar-scale: Scale that determines how much of excess variance "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" a particular direction gets attributed to between-class covar. "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("float, default "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n  --binary: Write output "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" binary mode "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("bool, default "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n  --mean-diff-scale: Scale with "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("which")]),a._v(" to "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("add")]),a._v(" to the total data variance, the outer product of the difference between the original mean and the adaptation-data mean "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("float, default "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n  --within-covar-scale: Scale that determines how much of excess variance "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" a particular direction gets attributed to within-class covar. "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("float, default "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br"),s("span",{staticClass:"line-number"},[a._v("6")]),s("br"),s("span",{staticClass:"line-number"},[a._v("7")]),s("br"),s("span",{staticClass:"line-number"},[a._v("8")]),s("br")])]),s("h3",{attrs:{id:"主要流程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#主要流程"}},[a._v("#")]),a._v(" 主要流程")])])}),[],!1,null,null,null);t.default=r.exports}}]);