(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{429:function(e,r,t){"use strict";t.r(r);var n=t(10),a=Object(n.a)({},(function(){var e=this,r=e.$createElement,t=e._self._c||r;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("ul",[t("li",[t("a",{attrs:{href:"https://blog.csdn.net/qq_27245709/article/details/91469688",target:"_blank",rel:"noopener noreferrer"}},[e._v("几种矩阵分解算法： LU分解，Cholesky分解，QR分解，SVD分解，Jordan分解"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://www.cnblogs.com/brains/p/3617771.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("服从正太分布的随机向量经线性变换后的协方差矩阵"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/66067740",target:"_blank",rel:"noopener noreferrer"}},[e._v("从线性变换的角度看高斯分布协方差阵的意义"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://blog.csdn.net/joker_shy/article/details/98761650",target:"_blank",rel:"noopener noreferrer"}},[e._v("机器学习——特征值分解"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://wenku.baidu.com/view/4f60f8a40029bd64783e2cbd.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("实对称矩阵的特征值和特征向量"),t("OutboundLink")],1)])]),e._v(" "),t("h2",{attrs:{id:"特征处理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#特征处理"}},[e._v("#")]),e._v(" 特征处理")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://www.cnblogs.com/pinard/p/6244265.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("线性判别分析LDA原理总结 - 刘建平Pinard - 博客园 (cnblogs.com)"),t("OutboundLink")],1)]),e._v(" "),t("li")])])}),[],!1,null,null,null);r.default=a.exports}}]);